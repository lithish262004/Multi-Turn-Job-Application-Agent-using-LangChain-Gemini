{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lithish262004/Multi-Turn-Job-Application-Agent-using-LangChain-Gemini/blob/main/JOB_APPLICATION_AGENT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrnwCRmxLgzR"
      },
      "source": [
        "Building a Multi-Turn Job Application Agent Using LangChain & Gemini\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tpaJNcaNhcJ"
      },
      "source": [
        "STEP 1: INSTALLING REQUIREED PACKAGES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vWjR81Uc4lwi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9482ebd-fcd7-4401-9931-8b22b885fc8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/42.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchain-google-genai google-generativeai gradio pydantic\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 2: IMPORTING LIBRARIES AND API KEY"
      ],
      "metadata": {
        "id": "6IfmDVyGlzu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gradio as gr\n",
        "from pydantic import BaseModel\n",
        "from langchain.tools import tool\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "# Set your Google API key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAiK1VNt6g8npc1-EByNX2GImA0giunwF8\"\n"
      ],
      "metadata": {
        "id": "85nsb0Qwke7O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 3: OUTPUT SCHEMA"
      ],
      "metadata": {
        "id": "yzKyUIh5l81y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ApplicationOutput(BaseModel):\n",
        "    job_title: str\n",
        "    cover_letter: str\n",
        "\n",
        "@tool\n",
        "def save_application(job_title: str, cover_letter: str) -> str:\n",
        "    \"\"\"Save the job application and return confirmation.\"\"\"\n",
        "    return f\"Application for '{job_title}' saved successfully.\"\n",
        "\n",
        "tools = [save_application]\n"
      ],
      "metadata": {
        "id": "mlF4aQAIke92"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 4: LOAD LLM,PROMPT & AGENT"
      ],
      "metadata": {
        "id": "0iPOoTHQmDXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    temperature=0.3,\n",
        "    max_output_tokens=1500\n",
        ")\n",
        "\n",
        "parser = PydanticOutputParser(pydantic_object=ApplicationOutput)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"\n",
        "You are a career assistant that helps tailor resumes and write cover letters for job applications.\n",
        "\n",
        "Use the provided resume and job description to:\n",
        "1. Understand job requirements\n",
        "2. Modify the resume to align with key skills\n",
        "3. Generate a professional, personalized cover letter\n",
        "\n",
        "Always save the result using the save_application tool.\n",
        "\n",
        "Output only valid JSON in this format:\n",
        "{format_instructions}\n",
        "\"\"\"),\n",
        "    (\"placeholder\", \"{chat_history}\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"placeholder\", \"{agent_scratchpad}\")\n",
        "]).partial(format_instructions=parser.get_format_instructions())\n",
        "\n",
        "agent = create_tool_calling_agent(\n",
        "    llm=llm,\n",
        "    prompt=prompt,\n",
        "    tools=tools\n",
        ")\n",
        "\n",
        "executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n"
      ],
      "metadata": {
        "id": "OaV_nCTckfAf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 5: GRADIO CHATBOT"
      ],
      "metadata": {
        "id": "m2XyborfmJ3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = []\n",
        "\n",
        "def chat_fn(user_input, history):\n",
        "    chat_history_obj = []\n",
        "\n",
        "    for msg in history:\n",
        "        chat_history_obj.append(HumanMessage(content=msg[0]))\n",
        "        chat_history_obj.append(AIMessage(content=msg[1]))\n",
        "\n",
        "    chat_history_obj.append(HumanMessage(content=user_input))\n",
        "\n",
        "    response = executor.invoke({\n",
        "        \"input\": user_input,\n",
        "        \"chat_history\": chat_history_obj\n",
        "    })\n",
        "\n",
        "    try:\n",
        "        parsed = parser.parse(response.get(\"output\"))\n",
        "        reply = f\"‚úÖ Job Title: {parsed.job_title}\\n\\nüìÑ Cover Letter:\\n{parsed.cover_letter}\"\n",
        "    except:\n",
        "        reply = response.get(\"output\", \"‚ö†Ô∏è Could not parse response\")\n",
        "\n",
        "    return history + [(user_input, reply)]\n"
      ],
      "metadata": {
        "id": "bpb7vI-ZkfCz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 6: LAUNCH GRADIO CHATBOT"
      ],
      "metadata": {
        "id": "6u5w3GnbmQ0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## ü§ñ Job Application Agent (LangChain + Gemini)\")\n",
        "    chatbot = gr.Chatbot()\n",
        "    user_input = gr.Textbox(placeholder=\"Ask me to apply for a job...\", show_label=False)\n",
        "\n",
        "    user_input.submit(chat_fn, [user_input, chatbot], chatbot)\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "gwuhFpoakfFV",
        "outputId": "a4d8cbb4-d5ad-4f1c-e121-0e971c990c2d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-8-3621635354.py:3: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://89389228a0d752dd9d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://89389228a0d752dd9d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHiAdM80XHP65Z9XCx/rZG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}